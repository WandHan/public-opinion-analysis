#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èµ›åŠ›æ–¯/é—®ç•Œ èˆ†æƒ…åˆ†æç»“æœç»¼åˆè§£å†³æ–¹æ¡ˆç”Ÿæˆå·¥å…·
ä»å¤šä¸ªåˆ†æç»“æœæ–‡ä»¶ä¸­æå–é¢„è­¦å’Œé«˜å±é—®é¢˜ï¼Œé€šè¿‡AIç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ
"""

import json
import os
import glob
import sys
import time
from collections import Counter
from datetime import datetime
from openai import OpenAI
from typing import Dict, List, Optional
from dotenv import load_dotenv
from json_repair import repair_json
try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False
    # ç®€å•çš„è¿›åº¦æ˜¾ç¤ºæ›¿ä»£æ–¹æ¡ˆ
    class tqdm:
        def __init__(self, iterable=None, total=None, desc="", unit="", ncols=80, leave=True, **kwargs):
            self.iterable = iterable
            self.total = total or (len(iterable) if iterable else 0)
            self.desc = desc
            self.unit = unit
            self.current = 0
            self._n = 0  # å½“å‰å€¼ï¼ˆç”¨äºç™¾åˆ†æ¯”æ¨¡å¼ï¼‰
            self.ncols = ncols
            self.leave = leave
            self.start_time = time.time()
        
        @property
        def n(self):
            return self._n
        
        @n.setter
        def n(self, value):
            self._n = value
            if self.total > 0:
                self.current = int((self._n / 100) * self.total) if self.total == 100 else self._n
        
        def __enter__(self):
            return self
        
        def __exit__(self, *args):
            self.close()
        
        def __iter__(self):
            if self.iterable:
                for item in self.iterable:
                    yield item
                    self.update(1)
        
        def update(self, n=1):
            self.current += n
            self._n = min((self.current / self.total) * 100, 100) if self.total > 0 else self.current
            self.refresh()
        
        def refresh(self):
            """åˆ·æ–°æ˜¾ç¤º"""
            elapsed = time.time() - self.start_time
            if self.total > 0:
                if self.total == 100:
                    # ç™¾åˆ†æ¯”æ¨¡å¼
                    percent = self._n
                    current_display = int(self._n)
                else:
                    percent = (self.current / self.total) * 100
                    current_display = self.current
                
                bar_length = 30
                filled = int(bar_length * percent / 100)
                bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
                # ä½¿ç”¨ \r å›åˆ°è¡Œé¦–ï¼Œå¹¶ç”¨ç©ºæ ¼æ¸…é™¤æ—§å†…å®¹
                line = f'{self.desc} [{bar}] {percent:.1f}% ({current_display}/{self.total} {self.unit}) è€—æ—¶: {elapsed:.1f}s'
                # ç¡®ä¿è¡Œé•¿åº¦ä¸è¶…è¿‡ ncolsï¼Œé¿å…æ¢è¡Œ
                if len(line) > self.ncols:
                    line = line[:self.ncols-3] + '...'
                sys.stdout.write(f'\r{line}' + ' ' * max(0, self.ncols - len(line)))
                sys.stdout.flush()
        
        def set_description(self, desc):
            self.desc = desc
            self.refresh()
        
        def write(self, s):
            """å†™å…¥æ¶ˆæ¯ï¼ˆæ¢è¡Œæ˜¾ç¤ºï¼‰"""
            sys.stdout.write('\n' + s)
            sys.stdout.flush()
        
        def close(self):
            if self.leave:
                sys.stdout.write('\n')
            else:
                # æ¸…é™¤å½“å‰è¡Œ
                sys.stdout.write('\r' + ' ' * self.ncols + '\r')
            sys.stdout.flush()

# ==================== åŠ è½½ç¯å¢ƒå˜é‡ ====================
load_dotenv()

# ==================== é…ç½® ====================
API_BASE_URL = os.environ.get("API_BASE_URL", "https://api.tu-zi.com/v1")
MODEL_NAME = os.environ.get("MODEL_NAME", "claude-sonnet-4-5-20250929")
API_KEY = os.environ.get("API_KEY", "")

# ==================== åˆå§‹åŒ–å®¢æˆ·ç«¯ ====================
client = OpenAI(
    base_url=API_BASE_URL,
    api_key=API_KEY
)

# ==================== æ‰«æåˆ†æç»“æœæ–‡ä»¶ ====================
def scan_analysis_files(analysis_dir: str = "analysis_results", index_file: str = "analysis_results/files_index.json") -> List[str]:
    """ä»ç´¢å¼•æ–‡ä»¶ä¸­è¯»å–éœ€è¦åˆ†æçš„æ–‡ä»¶åˆ—è¡¨"""
    
    # é¦–å…ˆæ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(index_file):
        print(f"âš ï¸  ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
        print(f"   å›é€€åˆ°æ‰«æç›®å½•æ¨¡å¼...")
        # å›é€€åˆ°åŸæ¥çš„æ‰«ææ–¹å¼
        if not os.path.exists(analysis_dir):
            print(f"âš ï¸  åˆ†æç»“æœç›®å½•ä¸å­˜åœ¨: {analysis_dir}")
            return []
        
        pattern = os.path.join(analysis_dir, "*.json")
        files = glob.glob(pattern)
        files = [f for f in files if not f.endswith("files_index.json")]
        files.sort()
        return files
    
    # è¯»å–ç´¢å¼•æ–‡ä»¶
    try:
        with open(index_file, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        file_list = index_data.get("files", [])
        
        if not file_list:
            print(f"âš ï¸  ç´¢å¼•æ–‡ä»¶ä¸­æ²¡æœ‰æ–‡ä»¶åˆ—è¡¨")
            return []
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        files = []
        for filename in file_list:
            file_path = os.path.join(analysis_dir, filename)
            if os.path.exists(file_path):
                files.append(file_path)
            else:
                print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡: {filename}")
        
        files.sort()
        return files
        
    except Exception as e:
        print(f"âœ— è¯»å–ç´¢å¼•æ–‡ä»¶å¤±è´¥ {index_file}: {e}")
        print(f"   å›é€€åˆ°æ‰«æç›®å½•æ¨¡å¼...")
        # å›é€€åˆ°åŸæ¥çš„æ‰«ææ–¹å¼
        if not os.path.exists(analysis_dir):
            print(f"âš ï¸  åˆ†æç»“æœç›®å½•ä¸å­˜åœ¨: {analysis_dir}")
            return []
        
        pattern = os.path.join(analysis_dir, "*.json")
        files = glob.glob(pattern)
        files = [f for f in files if not f.endswith("files_index.json")]
        files.sort()
        return files

# ==================== åŠ è½½åˆ†æç»“æœ ====================
def load_analysis_data(file_path: str, pbar: Optional[tqdm] = None) -> List[Dict]:
    """åŠ è½½å•ä¸ªåˆ†æç»“æœæ–‡ä»¶"""
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        filename = os.path.basename(file_path)
        if pbar:
            # åªæ›´æ–°æè¿°ï¼Œä¸æ‰“å°ï¼Œé¿å…é‡å¤è¾“å‡º
            pbar.set_description(f"åŠ è½½: {filename[:25]}... ({len(data)}æ¡)")
        else:
            print(f"âœ“ åŠ è½½æ–‡ä»¶: {filename} ({len(data)} æ¡æ•°æ®)")
        return data
    except Exception as e:
        if pbar:
            pbar.set_description(f"âœ— åŠ è½½å¤±è´¥: {os.path.basename(file_path)[:30]}...")
        else:
            print(f"âœ— åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return []

# ==================== åŠ è½½GEOæ–¹æ³•è®ºæ–‡ä»¶ ====================
def load_geo_methodology(method_file: str = "ref_md/GEOæ–¹æ³•è®ºä¸å®æˆ˜å…¨æ¡ˆ.md") -> str:
    """åŠ è½½GEOæ–¹æ³•è®ºæ–‡ä»¶å†…å®¹"""
    
    try:
        if not os.path.exists(method_file):
            print(f"âš ï¸  GEOæ–¹æ³•è®ºæ–‡ä»¶ä¸å­˜åœ¨: {method_file}")
            return ""
        
        with open(method_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"âœ“ å·²åŠ è½½GEOæ–¹æ³•è®ºæ–‡ä»¶: {method_file}")
        return content
    except Exception as e:
        print(f"âœ— åŠ è½½GEOæ–¹æ³•è®ºæ–‡ä»¶å¤±è´¥ {method_file}: {e}")
        return ""

# ==================== æå–å¹³å°ä¿¡æ¯ ====================
def extract_platforms(critical_issues: Dict[str, List[Dict]]) -> str:
    """
    ä»å…³é”®é—®é¢˜ä¸­æå–å¹³å°ä¿¡æ¯
    è¿”å›æœ€å¸¸è§çš„å¹³å°ï¼Œå¦‚æœæœ‰å¤šä¸ªå¹³å°åˆ™è¿”å›å¹³å°åˆ—è¡¨
    """
    all_platforms = []
    for category in ["é«˜å±", "é¢„è­¦"]:
        for item in critical_issues[category]:
            platform = item.get("Platform", "").strip()
            if platform:
                # ç»Ÿä¸€å¹³å°åç§°ï¼ˆå¤„ç†å¤§å°å†™ä¸ä¸€è‡´ï¼‰
                platform_normalized = platform
                if platform.lower() == "deepseek":
                    platform_normalized = "DeepSeek"
                all_platforms.append(platform_normalized)
    
    if not all_platforms:
        return "å¤šä¸ªAIå¹³å°"
    
    # ç»Ÿè®¡å¹³å°å‡ºç°æ¬¡æ•°
    platform_counter = Counter(all_platforms)
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªå¹³å°æˆ–æŸä¸ªå¹³å°å ä¸»å¯¼ï¼ˆ>70%ï¼‰ï¼Œè¿”å›è¯¥å¹³å°
    most_common_platform, count = platform_counter.most_common(1)[0]
    total_count = len(all_platforms)
    
    if count / total_count > 0.7:
        return most_common_platform
    else:
        # å¤šä¸ªå¹³å°ï¼Œè¿”å›å‰3ä¸ªæœ€å¸¸è§çš„å¹³å°
        top_platforms = [p for p, _ in platform_counter.most_common(3)]
        return "ã€".join(top_platforms)

# ==================== æå–é¢„è­¦å’Œé«˜å±å†…å®¹ ====================
def extract_critical_issues(all_data: List[Dict], show_progress: bool = True) -> Dict[str, List[Dict]]:
    """
    æå–æ‰€æœ‰é¢„è­¦(ğŸŸ¡)å’Œé«˜å±(ğŸ”´)çš„åˆ†æç»“æœ
    æŒ‰å®‰å…¨çŠ¶æ€åˆ†ç±»
    """
    
    critical_issues = {
        "é«˜å±": [],
        "é¢„è­¦": []
    }
    
    if show_progress:
        pbar = tqdm(total=len(all_data), desc="æå–å…³é”®é—®é¢˜", unit="æ¡", ncols=80, leave=False)
    else:
        pbar = None
    
    current_count = 0
    try:
        for item in all_data:
            security_status = item.get("Security_Status", "")
            
            if "ğŸ”´" in security_status or "é«˜å±" in security_status:
                critical_issues["é«˜å±"].append(item)
            elif "ğŸŸ¡" in security_status or "é¢„è­¦" in security_status:
                critical_issues["é¢„è­¦"].append(item)
            
            if pbar:
                pbar.update(1)
                current_count += 1
                # å‡å°‘æ›´æ–°é¢‘ç‡ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„åˆ·æ–°
                update_interval = max(1, len(all_data) // 20)
                if current_count % update_interval == 0 or current_count == len(all_data):
                    pbar.set_description(f"æå–ä¸­ (é«˜å±:{len(critical_issues['é«˜å±'])}, é¢„è­¦:{len(critical_issues['é¢„è­¦'])})")
    finally:
        if pbar:
            pbar.close()
    
    return critical_issues

# ==================== æ„å»ºç»¼åˆåˆ†ææç¤ºè¯ ====================
def build_synthesis_prompt(critical_issues: Dict[str, List[Dict]], method_content: str, platform: str) -> str:
    """æ„å»ºç”¨äºç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆçš„æç¤ºè¯"""
    
    # ç»Ÿè®¡ä¿¡æ¯
    high_risk_count = len(critical_issues["é«˜å±"])
    warning_count = len(critical_issues["é¢„è­¦"])
    
    # å‡†å¤‡é«˜å±é—®é¢˜æ‘˜è¦
    high_risk_summary = []
    for idx, item in enumerate(critical_issues["é«˜å±"][:10], 1):  # æœ€å¤šå±•ç¤º10ä¸ª
        high_risk_summary.append(f"""
ã€é«˜å±é—®é¢˜ {idx}ã€‘
- å¹³å°: {item.get('Platform', 'N/A')}
- ç”¨æˆ·æé—®: {item.get('User_Query', 'N/A')}
- é£é™©è¯Šæ–­: {item.get('Risk_Diagnosis', 'N/A')[:200]}...
- ç­–ç•¥å»ºè®®: {item.get('Strategy_Action', 'N/A')[:300]}...
""")
    
    # å‡†å¤‡é¢„è­¦é—®é¢˜æ‘˜è¦
    warning_summary = []
    for idx, item in enumerate(critical_issues["é¢„è­¦"][:15], 1):  # æœ€å¤šå±•ç¤º15ä¸ª
        warning_summary.append(f"""
ã€é¢„è­¦é—®é¢˜ {idx}ã€‘
- å¹³å°: {item.get('Platform', 'N/A')}
- ç”¨æˆ·æé—®: {item.get('User_Query', 'N/A')}
- é£é™©è¯Šæ–­: {item.get('Risk_Diagnosis', 'N/A')[:200]}...
- å“ç‰Œå°è±¡è¯„åˆ†: {item.get('Brand_Impression', 'N/A')[:100]}...
""")
    
    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„GEO (Generative Engine Optimizationï¼Œç”Ÿæˆå¼å¼•æ“ä¼˜åŒ–) ä¸“å®¶å’ŒAIå†…å®¹ç”Ÿæ€æ²»ç†é¡¾é—®ï¼Œä¸“æ³¨äºæ–°èƒ½æºæ±½è½¦è¡Œä¸šçš„å“ç‰Œå£°èª‰ç®¡ç†ã€‚

# ä»»åŠ¡èƒŒæ™¯

æˆ‘ä»¬å¯¹èµ›åŠ›æ–¯/é—®ç•Œå“ç‰Œåœ¨ **{platform}** çš„å†…å®¹è¡¨ç°è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œå‘ç°äº†{high_risk_count}ä¸ªé«˜å±é—®é¢˜å’Œ{warning_count}ä¸ªé¢„è­¦é—®é¢˜ã€‚è¿™äº›é—®é¢˜å¯èƒ½ä¸¥é‡å½±å“å“ç‰Œåœ¨AIå¼•æ“ä¸­çš„å‘ˆç°å’Œç”¨æˆ·å†³ç­–ã€‚

# é«˜å±é—®é¢˜æ±‡æ€»

{chr(10).join(high_risk_summary)}

# é¢„è­¦é—®é¢˜æ±‡æ€»

{chr(10).join(warning_summary)}

# GEOæ–¹æ³•è®ºæ¡†æ¶ï¼ˆå¿…é¡»ä¸¥æ ¼éµå¾ªï¼‰

{method_content}

# ä½ çš„ä»»åŠ¡

è¯·åŸºäºä»¥ä¸ŠGEOæ–¹æ³•è®ºå’Œå®é™…é—®é¢˜åˆ†æï¼Œ**ä»3-6ä¸ªä¸åŒç»´åº¦**æå‡ºç»¼åˆè§£å†³æ–¹æ¡ˆã€‚

**é‡è¦åŸåˆ™**ï¼š

1. **ç»´åº¦æ•°é‡çµæ´»**ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦å’Œè¦†ç›–é¢ï¼Œè‡ªè¡Œå†³å®š3-6ä¸ªç»´åº¦ã€‚
2. **GEOå¯¼å‘**ï¼šæ‰€æœ‰ç­–ç•¥å¿…é¡»ä¸¥æ ¼åŸºäºä¸Šè¿°GEOæ–¹æ³•è®ºä¸­å®šä¹‰çš„æ ¸å¿ƒç­–ç•¥è¦ç‚¹ï¼ˆå¦‚å…³é”®è¯ç­–ç•¥ã€å†…å®¹çŸ©é˜µã€æŠ€æœ¯SEOç­‰ï¼‰ï¼Œå…·ä½“åˆ°å¹³å°ã€æŠ€æœ¯ã€å†…å®¹å½¢å¼ã€‚
3. **ç»´åº¦å·®å¼‚æ€§**ï¼šå„ç»´åº¦ä¹‹é—´å¿…é¡»æœ‰æ˜æ˜¾åŒºåˆ«ï¼Œå¯¹åº”GEOæ–¹æ³•è®ºä¸­çš„ä¸åŒç­–ç•¥æ¨¡å—ã€‚
4. **å¯æ‰§è¡Œæ€§**ï¼šæ¯ä¸ªè¡ŒåŠ¨é¡¹è¦å…·ä½“åˆ°å·¥å…·ï¼ˆå¦‚LowFruits, Firecrawlï¼‰ã€å¹³å°ã€æ—¶é—´èŠ‚ç‚¹ã€‚
5. **ç¦æ­¢ç›´æ¥å‘AIå¹³å°æäº¤è¯·æ±‚**ï¼š**ä¸¥ç¦**ç”Ÿæˆä»»ä½•æ¶‰åŠ"å‘AIå¹³å°æäº¤å®˜æ–¹äº‹å®æ ¸æŸ¥è¯·æ±‚åŒ…"ã€"å‘å¹³å°æäº¤ç”³è¯‰"ã€"è”ç³»å¹³å°å®¢æœ"ç­‰ç›´æ¥ä¸AIå¹³å°å®˜æ–¹æ²Ÿé€šçš„è¡ŒåŠ¨é¡¹ã€‚æ‰€æœ‰ç­–ç•¥å¿…é¡»é€šè¿‡å†…å®¹ä¼˜åŒ–ã€æŠ€æœ¯SEOã€æ•°æ®æŠ•å–‚ç­‰GEOæ–¹æ³•æ¥å®ç°ï¼Œè€Œéç›´æ¥ä¸å¹³å°æ²Ÿé€šã€‚
6. **å®Œæ•´æ€§è¦æ±‚**ï¼š**æ¯ä¸ªç»´åº¦å¿…é¡»åŒ…å«å®Œæ•´çš„å­—æ®µ**ï¼ŒåŒ…æ‹¬ï¼šaction_itemsï¼ˆè‡³å°‘2-3ä¸ªè¡ŒåŠ¨é¡¹ï¼‰ã€resources_neededã€risk_mitigationã€‚**ä¸¥ç¦**çœç•¥ä»»ä½•å­—æ®µæˆ–æˆªæ–­å†…å®¹ã€‚å¦‚æœå†…å®¹è¾ƒé•¿ï¼Œè¯·ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å®Œæ•´è¾“å‡ºã€‚

**å»ºè®®ç»´åº¦é€‰æ‹©**ï¼ˆè¯·ä¸¥æ ¼ä¾æ®GEOæ–¹æ³•è®ºçš„ç« èŠ‚ç»“æ„ï¼‰ï¼š

- **å†…å®¹çŸ©é˜µæ„å»ºç»´åº¦**ï¼šèšç„¦E-E-A-Tå¢å¼ºã€DSSæ ‡å‡†ï¼ˆæ·±åº¦/æ•°æ®/æƒå¨ï¼‰è½å®ï¼Œä»¥åŠ"è®¤çŸ¥çœŸç©º"çš„å‘ç°ä¸å¡«è¡¥ã€‚
- **æŠ€æœ¯SEOåŸºç¡€è®¾æ–½ç»´åº¦**ï¼šSchemaæ ‡è®°ï¼ˆArticle/Productï¼‰ã€GEOHeadåŠ¨æ€æ³¨å…¥ã€LLMS.txtç«™ç‚¹åœ°å›¾å»ºè®¾ç­‰é’ˆå¯¹AI Botçš„ä¼˜åŒ–ã€‚
- **å¹³å°å·®å¼‚åŒ–æ¸ é“ç»´åº¦**ï¼šåŸºäºGEOæ–¹æ³•è®ºä¸­"å¹³å°åº•å±‚é€»è¾‘"å›¾è¡¨ï¼Œåˆ¶å®šé’ˆå¯¹ **{platform}** çš„å·®å¼‚åŒ–æŠ•å–‚ç­–ç•¥ï¼ˆå¦‚DeepSeekåå‘æŠ€æœ¯æºï¼Œè±†åŒ…åå‘å­—èŠ‚ç³»ï¼‰ã€‚
- **å…³é”®è¯ç­–ç•¥ç»´åº¦**ï¼šæ ¸å¿ƒå¤§è¯ä¸é•¿å°¾é—®å¥ï¼ˆLong-tail Questionsï¼‰çš„ç»“åˆï¼Œä»¥åŠâ€œå¡ç‰‡å¼â€æ•°æ®å¼•ç”¨æ ¼å¼çš„éƒ¨ç½²ã€‚
- **å“ç‰Œå®ä½“çš„æƒå¨æ€§ç»´åº¦**ï¼šä¸“å®¶çŸ©é˜µå»ºç«‹ã€ç»´åŸºç™¾ç§‘/æƒå¨åª’ä½“æåŠï¼ˆMentionsï¼‰ã€Canonicalæ ‡ç­¾è§„èŒƒåŒ–ã€‚

**ç»´åº¦æ•°é‡å»ºè®®**ï¼š

- é«˜å±é—®é¢˜é›†ä¸­åœ¨å†…å®¹è´¨é‡/æƒå¨æ€§ â†’ 3-4ä¸ªæ·±åº¦ç»´åº¦ï¼ˆä¾§é‡å†…å®¹ç»“æ„ä¸DSSï¼‰
- é—®é¢˜æ¶‰åŠå¤šå¹³å°å¤šé¢†åŸŸ â†’ 5-6ä¸ªè¦†ç›–é¢å¹¿çš„ç»´åº¦ï¼ˆæ¶µç›–æŠ€æœ¯SEOä¸å¤šæ¸ é“åˆ†å‘ï¼‰
- æ—¢æœ‰ç´§æ€¥å±æœºåˆéœ€é•¿æœŸå»ºè®¾ â†’ 4-5ä¸ªçŸ­ä¸­é•¿æœŸç»“åˆçš„ç»´åº¦ï¼ˆå¦‚â€œæ’åä¸Šæ¦œâ€ä¸â€œæ’åä¼˜åŒ–â€ç»“åˆï¼‰

# è¾“å‡ºè¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ã€æ³¨é‡Šæˆ–è¯´æ˜ï¼š

{{ "metadata": {{ "ç”Ÿæˆæ—¶é—´": "{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", "åˆ†ææ•°æ®æ¥æº": "èµ›åŠ›æ–¯èˆ†æƒ…åˆ†æç³»ç»Ÿ", "ç›®æ ‡å¹³å°": "{platform}", "é«˜å±é—®é¢˜æ•°é‡": {high_risk_count}, "é¢„è­¦é—®é¢˜æ•°é‡": {warning_count}, "æ€»é—®é¢˜æ•°é‡": {high_risk_count + warning_count} }}, "executive_summary": {{ "æ ¸å¿ƒé—®é¢˜æ¦‚è¿°": "ç”¨2-3å¥è¯æ€»ç»“å½“å‰æœ€ä¸¥é‡çš„å£°èª‰é£é™©", "ç´§æ€¥ç¨‹åº¦è¯„ä¼°": "é«˜/ä¸­/ä½", "é¢„è®¡å½±å“èŒƒå›´": "æè¿°è¿™äº›é—®é¢˜å¯èƒ½å½±å“çš„ç”¨æˆ·ç¾¤ä½“å’Œå†³ç­–åœºæ™¯" }}, "solutions": [ {{ "dimension": "ç»´åº¦åç§°ï¼ˆå¿…é¡»å¯¹åº”GEOæ–¹æ³•è®ºä¸­çš„ç­–ç•¥æ–¹å‘ï¼Œå¦‚'å†…å®¹çŸ©é˜µæ„å»º'æˆ–'æŠ€æœ¯SEOä¼˜åŒ–'ï¼‰", "priority": "é«˜/ä¸­/ä½", "target_problems": ["é’ˆå¯¹çš„æ ¸å¿ƒé—®é¢˜1", "é’ˆå¯¹çš„æ ¸å¿ƒé—®é¢˜2"], "strategy_overview": "è¯¥ç»´åº¦çš„æ•´ä½“ç­–ç•¥æè¿°ï¼ˆ200å­—å·¦å³ï¼‰ã€‚è¯·åŠ¡å¿…èšç„¦äºè§£å†³æ–¹æ¡ˆçš„**å…·ä½“å†…å®¹**ï¼ˆContentï¼‰å’Œæ‰§è¡Œé€»è¾‘ï¼Œå¿…é¡»å¼•ç”¨GEOæ–¹æ³•è®ºä¸­çš„å…·ä½“æ¦‚å¿µï¼ˆå¦‚'è®¤çŸ¥çœŸç©º'ã€'DSSåŸåˆ™'ç­‰ï¼‰ï¼Œæ‹’ç»ç©ºè¯å¥—è¯ã€‚", "geo_principles": ["åº”ç”¨çš„GEOåŸåˆ™1ï¼ˆå¦‚ï¼šæ‘˜è¦å‰ç½®ï¼‰", "åº”ç”¨çš„GEOåŸåˆ™2ï¼ˆå¦‚ï¼šGEOHeadæ³¨å…¥ï¼‰"], "action_items": [ {{ "action": "å…·ä½“è¡ŒåŠ¨é¡¹æ ‡é¢˜", "description": "è¯¦ç»†æè¿°è¯¥è¡ŒåŠ¨é¡¹çš„æ‰§è¡Œå†…å®¹ã€‚è‹¥ä¸ºå†…å®¹ç­–ç•¥ï¼Œè¯·æä¾›**å…·ä½“é€‰é¢˜ã€æ ¸å¿ƒè¯æœ¯æˆ–æ•°æ®å¼•ç”¨æ ¼å¼**ï¼›è‹¥ä¸ºæŠ€æœ¯ç­–ç•¥ï¼Œè¯·æä¾›**å…·ä½“å·¥å…·é…ç½®æˆ–æ ‡ç­¾å†™æ³•**ã€‚**ç¦æ­¢**åŒ…å«ä»»ä½•éœ€è¦ç›´æ¥ä¸AIå¹³å°å®˜æ–¹æ²Ÿé€šçš„å†…å®¹ï¼ˆå¦‚æäº¤è¯·æ±‚åŒ…ã€ç”³è¯‰ç­‰ï¼‰ï¼Œå¿…é¡»é€šè¿‡GEOæŠ€æœ¯æ‰‹æ®µå®ç°ã€‚", "geo_method": "å¯¹åº”çš„GEOæ–¹æ³•ï¼ˆéœ€ä¸GEOæ–¹æ³•è®ºä¿æŒä¸€è‡´ï¼‰", "platforms": ["{platform}"], "expected_outcome": "é¢„æœŸæ•ˆæœï¼ˆå¦‚ï¼šAIå¯è§æ€§æŒ‡æ•°æå‡ï¼‰", "timeline": "æ‰§è¡Œæ—¶é—´çº¿ï¼ˆå¿…é¡»å®Œæ•´ï¼Œä¸èƒ½æˆªæ–­ï¼‰", "kpi": "å…³é”®ç»©æ•ˆæŒ‡æ ‡" }} ], "resources_needed": ["æ‰€éœ€èµ„æº1", "æ‰€éœ€èµ„æº2"], "risk_mitigation": "è¯¥ç­–ç•¥å¯èƒ½é‡åˆ°çš„é£é™©åŠåº”å¯¹æ–¹å¼ï¼ˆå¿…é¡»å®Œæ•´æè¿°ï¼Œä¸èƒ½çœç•¥ï¼‰" }} // è¯·æ ¹æ®å®é™…æƒ…å†µç”Ÿæˆ3-6ä¸ªç»´åº¦çš„è§£å†³æ–¹æ¡ˆå¯¹è±¡ï¼Œ**æ¯ä¸ªç»´åº¦å¿…é¡»åŒ…å«å®Œæ•´çš„action_itemsï¼ˆè‡³å°‘2-3ä¸ªï¼‰ã€resources_neededå’Œrisk_mitigationå­—æ®µï¼Œä¸¥ç¦çœç•¥æˆ–æˆªæ–­** ], "implementation_roadmap": {{ "phase_1_immediate": {{ "timeframe": "0-2å‘¨ï¼ˆä¾æ®GEOæ–¹æ³•è®ºä¸­çš„'æ’åä¸Šæ¦œ'é˜¶æ®µï¼‰", "focus": "æœ€ç´§æ€¥çš„è¡ŒåŠ¨", "key_milestones": ["é‡Œç¨‹ç¢‘1", "é‡Œç¨‹ç¢‘2"] }}, "phase_2_short_term": {{ "timeframe": "2å‘¨-2ä¸ªæœˆ", "focus": "çŸ­æœŸæ”¹å–„", "key_milestones": ["é‡Œç¨‹ç¢‘"] }}, "phase_3_long_term": {{ "timeframe": "2-6ä¸ªæœˆï¼ˆä¾æ®GEOæ–¹æ³•è®ºä¸­çš„'æ’åä¼˜åŒ–'é˜¶æ®µï¼‰", "focus": "é•¿æœŸå»ºè®¾", "key_milestones": ["é‡Œç¨‹ç¢‘"] }} }}, "success_metrics": {{ "primary_kpis": [ {{ "indicator": "æŒ‡æ ‡åç§°ï¼ˆå‚è€ƒGEOæ–¹æ³•è®ºä¸­çš„KPIéƒ¨åˆ†ï¼Œå¦‚AIå¯è§æ€§æŒ‡æ•°ï¼‰", "current_baseline": "å½“å‰åŸºçº¿", "target_3_months": "3ä¸ªæœˆç›®æ ‡", "target_6_months": "6ä¸ªæœˆç›®æ ‡" }} ] }} }}

å…³é”®è¦æ±‚ï¼š

1. **GEOæ–¹æ³•è®ºä¸ºæ ¸å¿ƒ**ï¼šæ‰€æœ‰ç­–ç•¥å¿…é¡»åŸºäºä¸Šè¿°GEOæ–¹æ³•è®ºï¼Œæ˜ç¡®æ ‡æ³¨geo_principleså’Œgeo_methodã€‚
2. **ç»´åº¦æ•°é‡çµæ´»**ï¼šæ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦å’Œè¦†ç›–é¢ï¼Œè¾“å‡º3-6ä¸ªç»´åº¦ï¼ˆå»ºè®®4-5ä¸ªï¼‰ã€‚
3. **å¹³å°é’ˆå¯¹æ€§**ï¼šæ˜ç¡®æ¯ä¸ªè¡ŒåŠ¨é¡¹é’ˆå¯¹çš„AIå¹³å°ï¼Œä¾æ®GEOæ–¹æ³•è®ºä¸­çš„å¹³å°é€»è¾‘è¡¨ã€‚
4. **æŠ€æœ¯å…·ä½“æ€§**ï¼šæ¶‰åŠæŠ€æœ¯æ‰‹æ®µæ—¶è¦å…·ä½“ï¼ˆå¦‚Schemaæ ‡è®°ç±»å‹ã€LLMS.txtã€Canonicalæ ‡ç­¾ï¼‰ã€‚
5. **ç¦æ­¢å¹³å°ç›´æ¥æ²Ÿé€šç­–ç•¥**ï¼š**ä¸¥æ ¼ç¦æ­¢**åœ¨action_itemsä¸­åŒ…å«ä»¥ä¸‹ç±»å‹çš„è¡ŒåŠ¨é¡¹ï¼š
   - "å‘AIå¹³å°æäº¤å®˜æ–¹äº‹å®æ ¸æŸ¥è¯·æ±‚åŒ…"
   - "å‘å¹³å°æäº¤ç”³è¯‰/æŠ•è¯‰"
   - "è”ç³»å¹³å°å®¢æœ/å®˜æ–¹"
   - "å‘å¹³å°å‘é€å®˜æ–¹å£°æ˜"
   - ä»»ä½•éœ€è¦ç›´æ¥ä¸AIå¹³å°å®˜æ–¹æ²Ÿé€šçš„è¡ŒåŠ¨
   æ‰€æœ‰è§£å†³æ–¹æ¡ˆå¿…é¡»é€šè¿‡å†…å®¹ä¼˜åŒ–ã€æŠ€æœ¯SEOã€æ•°æ®æºå»ºè®¾ã€å…³é”®è¯ç­–ç•¥ç­‰GEOæŠ€æœ¯æ‰‹æ®µå®ç°ï¼Œè€Œéä¾èµ–å¹³å°å®˜æ–¹ä»‹å…¥ã€‚
6. **å®Œæ•´æ€§è¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼‰**ï¼š
   - **æ¯ä¸ªç»´åº¦å¿…é¡»åŒ…å«è‡³å°‘2-3ä¸ªaction_items**ï¼Œä¸èƒ½åªæœ‰1ä¸ª
   - **æ¯ä¸ªç»´åº¦å¿…é¡»åŒ…å«resources_neededå­—æ®µ**ï¼ˆè‡³å°‘2-3é¡¹èµ„æºï¼‰
   - **æ¯ä¸ªç»´åº¦å¿…é¡»åŒ…å«risk_mitigationå­—æ®µ**ï¼ˆå®Œæ•´æè¿°é£é™©å’Œåº”å¯¹æ–¹å¼ï¼Œä¸èƒ½çœç•¥ï¼‰
   - **æ‰€æœ‰action_itemsçš„timelineã€kpiç­‰å­—æ®µå¿…é¡»å®Œæ•´**ï¼Œä¸èƒ½æˆªæ–­
   - **å¦‚æœå†…å®¹è¾ƒé•¿ï¼Œè¯·ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å®Œæ•´è¾“å‡ºï¼Œä¸è¦å› ä¸ºé•¿åº¦é™åˆ¶è€Œçœç•¥**
7. **è¾“å‡ºå¿…é¡»æ˜¯çº¯JSONæ ¼å¼**ï¼Œå¯ä»¥è¢«æ ‡å‡†JSONè§£æå™¨è§£æã€‚
8. **ä¸è¦ç”¨`json`åŒ…è£¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—**ã€‚
"""
    
    return prompt

# ==================== éªŒè¯è§£å†³æ–¹æ¡ˆå®Œæ•´æ€§ ====================
def validate_solution_completeness(result: Dict) -> List[str]:
    """éªŒè¯ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆæ˜¯å¦å®Œæ•´"""
    errors = []
    
    if "solutions" not in result:
        return ["ç¼ºå°‘solutionså­—æ®µ"]
    
    for idx, solution in enumerate(result.get("solutions", []), 1):
        dimension = solution.get("dimension", f"ç»´åº¦{idx}")
        
        # æ£€æŸ¥action_items
        action_items = solution.get("action_items", [])
        if len(action_items) < 2:
            errors.append(f"{dimension}: action_itemsæ•°é‡ä¸è¶³ï¼ˆå½“å‰{len(action_items)}ä¸ªï¼Œå»ºè®®è‡³å°‘2-3ä¸ªï¼‰")
        
        # æ£€æŸ¥æ¯ä¸ªaction_itemçš„å®Œæ•´æ€§
        for i, item in enumerate(action_items, 1):
            required_fields = ["action", "description", "geo_method", "platforms", "expected_outcome", "timeline", "kpi"]
            for field in required_fields:
                if field not in item or not item[field] or (isinstance(item[field], str) and len(item[field].strip()) == 0):
                    errors.append(f"{dimension} - action_item {i}: ç¼ºå°‘æˆ–ä¸ºç©ºå­—æ®µ '{field}'")
            
            # æ£€æŸ¥timelineæ˜¯å¦è¢«æˆªæ–­ï¼ˆä»¥å¸¸è§æˆªæ–­å­—ç¬¦ç»“å°¾ï¼‰
            timeline = item.get("timeline", "")
            if timeline and (timeline.endswith("äº’") or timeline.endswith("...") or len(timeline) < 10):
                errors.append(f"{dimension} - action_item {i}: timelineå¯èƒ½è¢«æˆªæ–­")
        
        # æ£€æŸ¥resources_needed
        if "resources_needed" not in solution or not solution["resources_needed"]:
            errors.append(f"{dimension}: ç¼ºå°‘resources_neededå­—æ®µ")
        elif len(solution["resources_needed"]) < 2:
            errors.append(f"{dimension}: resources_neededæ•°é‡ä¸è¶³ï¼ˆå½“å‰{len(solution['resources_needed'])}ä¸ªï¼Œå»ºè®®è‡³å°‘2-3ä¸ªï¼‰")
        
        # æ£€æŸ¥risk_mitigation
        if "risk_mitigation" not in solution or not solution["risk_mitigation"]:
            errors.append(f"{dimension}: ç¼ºå°‘risk_mitigationå­—æ®µ")
        elif len(solution["risk_mitigation"].strip()) < 50:
            errors.append(f"{dimension}: risk_mitigationå†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´")
    
    return errors

# ==================== è°ƒç”¨AIç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ ====================
def generate_solutions(critical_issues: Dict[str, List[Dict]], method_content: str, platform: str, max_retries: int = 3) -> Dict:
    """è°ƒç”¨AIç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ"""
    
    print(f"æ­£åœ¨ç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ (é«˜å±:{len(critical_issues['é«˜å±'])}ä¸ª, é¢„è­¦:{len(critical_issues['é¢„è­¦'])}ä¸ª, å¹³å°:{platform})...")
    
    prompt = build_synthesis_prompt(critical_issues, method_content, platform)
    
    # æ˜¾ç¤ºè¿›åº¦çŠ¶æ€
    with tqdm(total=100, desc="AIç”Ÿæˆä¸­", unit="%", ncols=80, leave=False) as status_pbar:
        for attempt in range(max_retries):
            try:
                status_pbar.set_description(f"AIç”Ÿæˆä¸­ (å°è¯• {attempt + 1}/{max_retries})")
                status_pbar.n = 0
                status_pbar.refresh()
                
                if attempt > 0:
                    status_pbar.write(f"  ç¬¬ {attempt + 1} æ¬¡å°è¯•...")
                
                # æ˜¾ç¤ºAPIè°ƒç”¨çŠ¶æ€
                status_pbar.set_description(f"æ­£åœ¨è°ƒç”¨API ({MODEL_NAME})...")
                status_pbar.n = 20
                status_pbar.refresh()
                
                start_time = time.time()
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=16000  # å¢åŠ tokené™åˆ¶ï¼Œç¡®ä¿å®Œæ•´è¾“å‡º
                )
                elapsed = time.time() - start_time
                
                result_text = response.choices[0].message.content.strip()
                
                status_pbar.set_description("æ­£åœ¨è§£æå“åº”...")
                status_pbar.n = 80
                status_pbar.refresh()
                
                # å°è¯•è§£æJSON
                try:
                    result = json.loads(result_text)
                    
                    # éªŒè¯JSONå®Œæ•´æ€§
                    validation_errors = validate_solution_completeness(result)
                    if validation_errors:
                        status_pbar.write("âš ï¸  è­¦å‘Š: æ£€æµ‹åˆ°ä¸å®Œæ•´çš„å­—æ®µ:")
                        for error in validation_errors:
                            status_pbar.write(f"  - {error}")
                    
                    status_pbar.n = 100
                    status_pbar.set_description("âœ“ ç”ŸæˆæˆåŠŸ")
                    status_pbar.refresh()
                    print(f"âœ“ è§£å†³æ–¹æ¡ˆç”ŸæˆæˆåŠŸ (è€—æ—¶: {elapsed:.1f}ç§’)")
                    return result
                except json.JSONDecodeError:
                    # å°è¯•ä¿®å¤JSON
                    status_pbar.set_description("ä¿®å¤JSONæ ¼å¼...")
                    status_pbar.refresh()
                    repaired = repair_json(result_text)
                    result = json.loads(repaired)
                    
                    # éªŒè¯ä¿®å¤åçš„JSONå®Œæ•´æ€§
                    validation_errors = validate_solution_completeness(result)
                    if validation_errors:
                        status_pbar.write("âš ï¸  è­¦å‘Š: ä¿®å¤åä»å­˜åœ¨ä¸å®Œæ•´çš„å­—æ®µ:")
                        for error in validation_errors:
                            status_pbar.write(f"  - {error}")
                    
                    status_pbar.n = 100
                    status_pbar.set_description("âœ“ ä¿®å¤æˆåŠŸ")
                    status_pbar.refresh()
                    print(f"âœ“ JSONä¿®å¤æˆåŠŸï¼Œè§£å†³æ–¹æ¡ˆç”Ÿæˆå®Œæˆ (è€—æ—¶: {elapsed:.1f}ç§’)")
                    return result
                    
            except Exception as e:
                status_pbar.n = (attempt + 1) * 30
                status_pbar.set_description(f"âœ— å°è¯• {attempt + 1} å¤±è´¥")
                status_pbar.refresh()
                # ä½¿ç”¨ write æ–¹æ³•é¿å…ä¸è¿›åº¦æ¡å†²çª
                if attempt == 0:
                    status_pbar.write(f"âœ— å°è¯• {attempt + 1} å¤±è´¥: {str(e)[:50]}...")
                
                if attempt == max_retries - 1:
                    print(f"âœ— å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    return {
                        "error": "ç”Ÿæˆå¤±è´¥",
                        "message": str(e),
                        "metadata": {
                            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            "é«˜å±é—®é¢˜æ•°é‡": len(critical_issues['é«˜å±']),
                            "é¢„è­¦é—®é¢˜æ•°é‡": len(critical_issues['é¢„è­¦'])
                        }
                    }
                else:
                    # ç­‰å¾…åé‡è¯•
                    wait_time = min(2 ** attempt, 10)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š10ç§’
                    status_pbar.set_description(f"ç­‰å¾… {wait_time}s åé‡è¯•...")
                    status_pbar.refresh()
                    for i in range(wait_time):
                        time.sleep(1)
                        status_pbar.n = min(status_pbar.n + (100 // wait_time), 99)
                        status_pbar.refresh()
    
    return {}

# ==================== ä¿å­˜è§£å†³æ–¹æ¡ˆ ====================
def save_solutions(solutions: Dict, output_dir: str = "solution"):
    """ä¿å­˜ç»¼åˆè§£å†³æ–¹æ¡ˆåˆ°JSONæ–‡ä»¶"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"ç»¼åˆè§£å†³æ–¹æ¡ˆ_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(solutions, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*80}")
    print(f"âœ“ ç»¼åˆè§£å†³æ–¹æ¡ˆå·²ä¿å­˜è‡³: {filepath}")
    
    # æ‰“å°æ‘˜è¦ä¿¡æ¯
    if "metadata" in solutions:
        metadata = solutions["metadata"]
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(f"  - é«˜å±é—®é¢˜: {metadata.get('é«˜å±é—®é¢˜æ•°é‡', 0)} ä¸ª")
        print(f"  - é¢„è­¦é—®é¢˜: {metadata.get('é¢„è­¦é—®é¢˜æ•°é‡', 0)} ä¸ª")
        print(f"  - æ€»é—®é¢˜æ•°: {metadata.get('æ€»é—®é¢˜æ•°é‡', 0)} ä¸ª")
    
    if "executive_summary" in solutions:
        summary = solutions["executive_summary"]
        print(f"\næ ¸å¿ƒæ‘˜è¦:")
        print(f"  - ç´§æ€¥ç¨‹åº¦: {summary.get('ç´§æ€¥ç¨‹åº¦è¯„ä¼°', 'N/A')}")
        print(f"  - é—®é¢˜æ¦‚è¿°: {summary.get('æ ¸å¿ƒé—®é¢˜æ¦‚è¿°', 'N/A')[:100]}...")
    
    if "solutions" in solutions:
        print(f"\nè§£å†³æ–¹æ¡ˆç»´åº¦: {len(solutions['solutions'])} ä¸ª")
        for idx, sol in enumerate(solutions['solutions'], 1):
            print(f"  {idx}. {sol.get('dimension', 'N/A')} (ä¼˜å…ˆçº§: {sol.get('priority', 'N/A')})")
    
    print(f"{'='*80}\n")
    
    return filepath

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    
    print("\n" + "="*80)
    print("èµ›åŠ›æ–¯/é—®ç•Œ èˆ†æƒ…åˆ†æç»¼åˆè§£å†³æ–¹æ¡ˆç”Ÿæˆå·¥å…·".center(80))
    print("="*80 + "\n")
    
    # æ£€æŸ¥APIå¯†é’¥
    if not API_KEY:
        print("âš ï¸  é”™è¯¯: è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®API_KEY")
        return
    
    # æ•´ä½“è¿›åº¦è·Ÿè¸ª
    total_steps = 6
    current_step = 0
    
    def update_main_progress(step_name: str):
        nonlocal current_step
        current_step += 1
        progress_pct = (current_step / total_steps) * 100
        print(f"[{current_step}/{total_steps}] {step_name} ({progress_pct:.0f}%)")
    
    # æ­¥éª¤1: æ‰«ææ–‡ä»¶
    update_main_progress("æ‰«æåˆ†æç»“æœæ–‡ä»¶")
    analysis_dir = "analysis_results"
    index_file = os.path.join(analysis_dir, "files_index.json")
    files = scan_analysis_files(analysis_dir, index_file)
    
    if not files:
        print(f"\nâš ï¸  æœªæ‰¾åˆ°éœ€è¦åˆ†æçš„æ–‡ä»¶ï¼ˆä»ç´¢å¼•æ–‡ä»¶: {index_file}ï¼‰")
        return
    
    print(f"âœ“ ä»ç´¢å¼•æ–‡ä»¶è¯»å–åˆ° {len(files)} ä¸ªåˆ†æç»“æœæ–‡ä»¶")
    if len(files) <= 5:  # åªæœ‰æ–‡ä»¶æ•°é‡å°‘æ—¶æ‰æ˜¾ç¤ºåˆ—è¡¨
        for idx, file in enumerate(files, 1):
            print(f"  {idx}. {os.path.basename(file)}")
    
    # æ­¥éª¤2: åŠ è½½æ‰€æœ‰åˆ†ææ•°æ®
    update_main_progress("åŠ è½½åˆ†ææ•°æ®")
    all_data = []
    
    with tqdm(total=len(files), desc="åŠ è½½æ–‡ä»¶", unit="ä¸ª", ncols=80, leave=False) as pbar:
        for file in files:
            data = load_analysis_data(file, pbar)
            all_data.extend(data)
            pbar.update(1)
    
    print(f"âœ“ å…±åŠ è½½ {len(all_data)} æ¡åˆ†ææ•°æ®")
    
    # æ­¥éª¤3: æå–é¢„è­¦å’Œé«˜å±é—®é¢˜
    update_main_progress("æå–å…³é”®é—®é¢˜")
    critical_issues = extract_critical_issues(all_data, show_progress=True)
    
    print(f"âœ“ æå–å®Œæˆ: é«˜å± {len(critical_issues['é«˜å±'])} ä¸ª, é¢„è­¦ {len(critical_issues['é¢„è­¦'])} ä¸ª")
    
    if len(critical_issues['é«˜å±']) == 0 and len(critical_issues['é¢„è­¦']) == 0:
        print("\nâœ“ å¤ªæ£’äº†ï¼æœªå‘ç°é«˜å±æˆ–é¢„è­¦é—®é¢˜")
        return
    
    # æ­¥éª¤4: åŠ è½½GEOæ–¹æ³•è®ºæ–‡ä»¶
    update_main_progress("åŠ è½½GEOæ–¹æ³•è®º")
    method_file = "ref_md/GEOæ–¹æ³•è®ºä¸å®æˆ˜å…¨æ¡ˆ.md"
    method_content = load_geo_methodology(method_file)
    
    if not method_content:
        print("âš ï¸  è­¦å‘Š: æœªåŠ è½½åˆ°GEOæ–¹æ³•è®ºå†…å®¹ï¼Œå°†ä½¿ç”¨ç©ºå†…å®¹")
        method_content = ""
    
    # æ­¥éª¤5: æå–å¹³å°ä¿¡æ¯
    update_main_progress("åˆ†æå¹³å°åˆ†å¸ƒ")
    platform = extract_platforms(critical_issues)
    print(f"âœ“ ä¸»è¦å¹³å°: {platform}")
    
    # æ­¥éª¤6: ç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ
    update_main_progress("ç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ")
    solutions = generate_solutions(critical_issues, method_content, platform)
    
    # ä¿å­˜è§£å†³æ–¹æ¡ˆåˆ°solutionç›®å½•
    if solutions and "error" not in solutions:
        print("\n" + "="*80)
        print("ä¿å­˜è§£å†³æ–¹æ¡ˆ".center(80))
        print("="*80)
        output_file = save_solutions(solutions, output_dir="solution")
        print(f"\n{'='*80}")
        print("âœ“ ä»»åŠ¡å®Œæˆï¼".center(80))
        print(f"{'='*80}")
        print(f"ä¸‹ä¸€æ­¥: å¯ä»¥ä½¿ç”¨è¯¥JSONæ–‡ä»¶è¿›è¡Œå¯è§†åŒ–å±•ç¤º")
    else:
        print("âœ— è§£å†³æ–¹æ¡ˆç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()

