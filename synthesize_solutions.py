#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èµ›åŠ›æ–¯/é—®ç•Œ èˆ†æƒ…åˆ†æç»“æœç»¼åˆè§£å†³æ–¹æ¡ˆç”Ÿæˆå·¥å…·
ä»å¤šä¸ªåˆ†æç»“æœæ–‡ä»¶ä¸­æå–é¢„è­¦å’Œé«˜å±é—®é¢˜ï¼Œé€šè¿‡AIç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ
"""

import json
import os
import glob
from datetime import datetime
from openai import OpenAI
from typing import Dict, List, Optional
from dotenv import load_dotenv
from json_repair import repair_json

# ==================== åŠ è½½ç¯å¢ƒå˜é‡ ====================
load_dotenv()

# ==================== é…ç½® ====================
API_BASE_URL = os.environ.get("API_BASE_URL", "https://api.tu-zi.com/v1")
MODEL_NAME = os.environ.get("MODEL_NAME", "claude-sonnet-4-5-20250929")
API_KEY = os.environ.get("API_KEY", "")

# ==================== åˆå§‹åŒ–å®¢æˆ·ç«¯ ====================
client = OpenAI(
    base_url=API_BASE_URL,
    api_key=API_KEY
)

# ==================== æ‰«æåˆ†æç»“æœæ–‡ä»¶ ====================
def scan_analysis_files(analysis_dir: str = "analysis_results") -> List[str]:
    """æ‰«æåˆ†æç»“æœç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶"""
    
    if not os.path.exists(analysis_dir):
        print(f"âš ï¸  åˆ†æç»“æœç›®å½•ä¸å­˜åœ¨: {analysis_dir}")
        return []
    
    pattern = os.path.join(analysis_dir, "*.json")
    files = glob.glob(pattern)
    
    # æ’é™¤ç´¢å¼•æ–‡ä»¶
    files = [f for f in files if not f.endswith("files_index.json")]
    files.sort()
    
    return files

# ==================== åŠ è½½åˆ†æç»“æœ ====================
def load_analysis_data(file_path: str) -> List[Dict]:
    """åŠ è½½å•ä¸ªåˆ†æç»“æœæ–‡ä»¶"""
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        print(f"âœ“ åŠ è½½æ–‡ä»¶: {os.path.basename(file_path)} ({len(data)} æ¡æ•°æ®)")
        return data
    except Exception as e:
        print(f"âœ— åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return []

# ==================== æå–é¢„è­¦å’Œé«˜å±å†…å®¹ ====================
def extract_critical_issues(all_data: List[Dict]) -> Dict[str, List[Dict]]:
    """
    æå–æ‰€æœ‰é¢„è­¦(ğŸŸ¡)å’Œé«˜å±(ğŸ”´)çš„åˆ†æç»“æœ
    æŒ‰å®‰å…¨çŠ¶æ€åˆ†ç±»
    """
    
    critical_issues = {
        "é«˜å±": [],
        "é¢„è­¦": []
    }
    
    for item in all_data:
        security_status = item.get("Security_Status", "")
        
        if "ğŸ”´" in security_status or "é«˜å±" in security_status:
            critical_issues["é«˜å±"].append(item)
        elif "ğŸŸ¡" in security_status or "é¢„è­¦" in security_status:
            critical_issues["é¢„è­¦"].append(item)
    
    return critical_issues

# ==================== æ„å»ºç»¼åˆåˆ†ææç¤ºè¯ ====================
def build_synthesis_prompt(critical_issues: Dict[str, List[Dict]]) -> str:
    """æ„å»ºç”¨äºç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆçš„æç¤ºè¯"""
    
    # ç»Ÿè®¡ä¿¡æ¯
    high_risk_count = len(critical_issues["é«˜å±"])
    warning_count = len(critical_issues["é¢„è­¦"])
    
    # å‡†å¤‡é«˜å±é—®é¢˜æ‘˜è¦
    high_risk_summary = []
    for idx, item in enumerate(critical_issues["é«˜å±"][:10], 1):  # æœ€å¤šå±•ç¤º10ä¸ª
        high_risk_summary.append(f"""
ã€é«˜å±é—®é¢˜ {idx}ã€‘
- å¹³å°: {item.get('Platform', 'N/A')}
- ç”¨æˆ·æé—®: {item.get('User_Query', 'N/A')}
- é£é™©è¯Šæ–­: {item.get('Risk_Diagnosis', 'N/A')[:200]}...
- ç­–ç•¥å»ºè®®: {item.get('Strategy_Action', 'N/A')[:300]}...
""")
    
    # å‡†å¤‡é¢„è­¦é—®é¢˜æ‘˜è¦
    warning_summary = []
    for idx, item in enumerate(critical_issues["é¢„è­¦"][:15], 1):  # æœ€å¤šå±•ç¤º15ä¸ª
        warning_summary.append(f"""
ã€é¢„è­¦é—®é¢˜ {idx}ã€‘
- å¹³å°: {item.get('Platform', 'N/A')}
- ç”¨æˆ·æé—®: {item.get('User_Query', 'N/A')}
- é£é™©è¯Šæ–­: {item.get('Risk_Diagnosis', 'N/A')[:200]}...
- å“ç‰Œå°è±¡è¯„åˆ†: {item.get('Brand_Impression', 'N/A')[:100]}...
""")
    
    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„GEO (Generative Engine Optimizationï¼Œç”Ÿæˆå¼å¼•æ“ä¼˜åŒ–) ä¸“å®¶å’ŒAIå†…å®¹ç”Ÿæ€æ²»ç†é¡¾é—®ï¼Œä¸“æ³¨äºæ–°èƒ½æºæ±½è½¦è¡Œä¸šçš„å“ç‰Œå£°èª‰ç®¡ç†ã€‚

# ä»»åŠ¡èƒŒæ™¯
æˆ‘ä»¬å¯¹èµ›åŠ›æ–¯/é—®ç•Œå“ç‰Œåœ¨å„å¤§AIå¹³å°ï¼ˆDeepSeekã€è±†åŒ…ã€å…ƒå®ã€Kimiç­‰ï¼‰çš„å†…å®¹è¡¨ç°è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œå‘ç°äº†{high_risk_count}ä¸ªé«˜å±é—®é¢˜å’Œ{warning_count}ä¸ªé¢„è­¦é—®é¢˜ã€‚è¿™äº›é—®é¢˜å¯èƒ½ä¸¥é‡å½±å“å“ç‰Œåœ¨AIå¼•æ“ä¸­çš„å‘ˆç°å’Œç”¨æˆ·å†³ç­–ã€‚

# é«˜å±é—®é¢˜æ±‡æ€»
{chr(10).join(high_risk_summary)}

# é¢„è­¦é—®é¢˜æ±‡æ€»
{chr(10).join(warning_summary)}

# GEOæ–¹æ³•è®ºæ¡†æ¶ï¼ˆå¿…é¡»éµå¾ªï¼‰

ä½ éœ€è¦åŸºäºæœ€æ–°çš„GEOæ–¹æ³•è®ºæ¥åˆ¶å®šè§£å†³æ–¹æ¡ˆã€‚æ ¸å¿ƒåŸåˆ™æ˜¯**"æŠ•AIæ‰€å¥½"**â€”â€”ä¸ºAIæ¨¡å‹æä¾›ç»“æ„åŒ–ã€æƒå¨ä¸”æ˜“äºå¼•ç”¨çš„"ä¿¡æ¯ç‡ƒæ–™"ã€‚

## GEOæ ¸å¿ƒç­–ç•¥è¦ç‚¹ï¼š

### 1. å†…å®¹ç”Ÿæ€å»ºè®¾ (Content Ecosystem)
- **E-E-A-TåŸåˆ™**ï¼šExperience(ç»éªŒ)ã€Expertise(ä¸“ä¸š)ã€Authoritativeness(æƒå¨)ã€Trustworthiness(å¯ä¿¡)
- **DSSè´¨é‡æ ‡å‡†**ï¼šDepth(è¯­ä¹‰æ·±åº¦)ã€Support(æ•°æ®æ”¯æŒ)ã€Source(æƒå¨æ¥æº)
- **ç»“æ„åŒ–å†…å®¹**ï¼šæ‘˜è¦å‰ç½®ã€Hæ ‡ç­¾å±‚çº§ã€çŸ­æ®µè½ã€FAQã€å¯¹æ¯”è¡¨æ ¼
- **"å¡ç‰‡å¼"æ•°æ®å¼•ç”¨**ï¼šé‡‡ç”¨"ç»“è®º+æ¥æº"æ ¼å¼ï¼Œå¦‚"æ ¹æ®ã€ŠXXç™½çš®ä¹¦ã€‹ï¼Œ75%ç”¨æˆ·è®¤ä¸º..."

### 2. æŠ€æœ¯è¯è¯­æƒä¸Schemaéƒ¨ç½²
- **Schemaæ ‡è®°**ï¼šArticleã€FAQPageã€Productã€Organizationç­‰ç»“æ„åŒ–æ•°æ®
- **GEOHeadåŠ¨æ€æ³¨å…¥**ï¼šå‘ç½‘é¡µæ³¨å…¥JSON-LDæè¿°æ ¸å¿ƒè¦ç‚¹ã€ä¸šåŠ¡èƒ½åŠ›
- **LLMS.txt**ï¼šä¸“ä¸ºAIçˆ¬è™«è®¾è®¡çš„ç«™ç‚¹åœ°å›¾
- **å“ç‰Œè¯çŸ©é˜µ**ï¼šæ ¸å¿ƒå¤§è¯+ç²¾å‡†é•¿å°¾è¯+å…³è”è¯

### 3. å¹³å°æ¸ é“ç­–ç•¥ï¼ˆé’ˆå¯¹ä¸åŒAIå¹³å°ï¼‰
- **DeepSeek**ï¼šæƒå¨ç½‘ç«™ã€GitHubã€ArXivã€æŠ€æœ¯åª’ä½“ï¼ˆ36æ°ªã€è™å—…ï¼‰
- **è±†åŒ…(å­—èŠ‚)**ï¼šå¤´æ¡å·ã€æŠ–éŸ³ã€æ‚Ÿç©ºé—®ç­”ã€ä»€ä¹ˆå€¼å¾—ä¹°
- **Kimi(æœˆä¹‹æš—é¢)**ï¼šçŸ¥ä¹ã€å…¬ä¼—å·ã€ç½‘æ˜“ã€æ–°æµªã€æœç‹
- **è…¾è®¯å…ƒå®**ï¼šå¾®ä¿¡å…¬ä¼—å·ã€æœä¸€æœ
- **å…±æ€§è§„å¾‹**ï¼šé«˜æƒé‡å‚ç›´ç«™ç‚¹ã€é«˜æ´»è·ƒè‡ªåª’ä½“ã€å‘å¸ƒæ—¶é—´é å‰

### 4. å†…å®¹åˆ›ä½œæœ€ä½³å®è·µ
- **æ’è¡Œæ¦œ/ç›˜ç‚¹ç±»**ï¼šæ•ˆæœæœ€å¥½ï¼ŒåŒ…å«æ—¶é—´(2025å¹´)ã€ç¬¬ä¸‰æ–¹ä¸­ç«‹è§’åº¦
- **é—®å¥ä¼˜åŒ–**ï¼šé•¿å°¾é—®å¥(å¦‚"2025å¹´é€‚åˆå®¶ç”¨çš„æ–°èƒ½æºSUVæœ‰å“ªäº›ï¼Ÿ")
- **å®¢è§‚å¹³è¡¡**ï¼šå±•ç¤ºä¼˜ç¼ºç‚¹ï¼Œé¿å…ç»å¯¹åŒ–ç”¨è¯("æœ€å¥½çš„"æ”¹ä¸º"åœ¨XXæ–¹é¢æ›´ä¼˜")
- **ä¸»é¢˜æƒå¨**ï¼šè½®è¾å¼å†…å®¹é›†ç¾¤ï¼Œæ”¯æŸ±é¡µé¢+æ·±åº¦èµ„æºé¡µ

### 5. æŠ€æœ¯SEOåŸºç¡€
- **AIçˆ¬è™«å‹å¥½**ï¼šå…è®¸GPTBotã€CCBotã€ClaudeBotç­‰
- **HTMLä¼˜å…ˆ**ï¼šæ ¸å¿ƒå†…å®¹ä¸ä¾èµ–JSåŠ¨æ€åŠ è½½
- **ç¦ç”¨nosnippet**ï¼šä¸¥ç¦ä½¿ç”¨max-snippet:0ç­‰é™åˆ¶AIå¼•ç”¨çš„æ ‡ç­¾
- **Canonicalæ ‡ç­¾**ï¼šæ˜ç¡®å†…å®¹åŸå§‹æƒå¨ç‰ˆæœ¬

### 6. æ•°æ®é©±åŠ¨ä¸ç›‘æµ‹
- **è®¤çŸ¥çœŸç©º**ï¼šå¯»æ‰¾AIå›ç­”æ¨¡ç³Šçš„é¢†åŸŸï¼Œå¡«è¡¥å†…å®¹è“æµ·
- **AIçˆ¬è™«ç›‘æµ‹**ï¼šæœåŠ¡å™¨æ—¥å¿—åˆ†æGPTBotè®¿é—®é¢‘ç‡
- **KPIæŒ‡æ ‡**ï¼šAIå¯è§æ€§æŒ‡æ•°ã€å¼•ç”¨ç‡ã€å†…å®¹å‡†ç¡®æ€§ã€ç›®æ ‡æç¤ºè¯è¦†ç›–ç‡

# ä½ çš„ä»»åŠ¡

è¯·åŸºäºä»¥ä¸ŠGEOæ–¹æ³•è®ºå’Œå®é™…é—®é¢˜åˆ†æï¼Œ**ä»3-6ä¸ªä¸åŒç»´åº¦**æå‡ºç»¼åˆè§£å†³æ–¹æ¡ˆã€‚

**é‡è¦åŸåˆ™**ï¼š
1. **ç»´åº¦æ•°é‡çµæ´»**ï¼šæ ¹æ®é—®é¢˜å¤æ‚åº¦å’Œè¦†ç›–é¢ï¼Œè‡ªè¡Œå†³å®š3-6ä¸ªç»´åº¦
2. **GEOå¯¼å‘**ï¼šæ‰€æœ‰ç­–ç•¥å¿…é¡»åŸºäºGEOæ–¹æ³•è®ºï¼Œå…·ä½“åˆ°å¹³å°ã€æŠ€æœ¯ã€å†…å®¹å½¢å¼
3. **ç»´åº¦å·®å¼‚æ€§**ï¼šå„ç»´åº¦ä¹‹é—´å¿…é¡»æœ‰æ˜æ˜¾åŒºåˆ«ï¼Œé¿å…é‡å¤æˆ–äº¤å‰
4. **å¯æ‰§è¡Œæ€§**ï¼šæ¯ä¸ªè¡ŒåŠ¨é¡¹è¦å…·ä½“åˆ°å·¥å…·ã€å¹³å°ã€æ—¶é—´èŠ‚ç‚¹

**å»ºè®®ç»´åº¦é€‰æ‹©**ï¼ˆæ ¹æ®å®é™…é—®é¢˜é€‰æ‹©å’Œç»„åˆï¼‰ï¼š
- **å†…å®¹ç”Ÿæ€é‡æ„**ï¼šE-E-A-Tæå‡ã€DSSå†…å®¹æ ‡å‡†ã€ç»“æ„åŒ–æ”¹é€ 
- **æŠ€æœ¯åŸºç¡€è®¾æ–½**ï¼šSchemaéƒ¨ç½²ã€LLMS.txtã€GEOHeadæ³¨å…¥ã€çˆ¬è™«ç›‘æµ‹
- **å¹³å°æ¸ é“çŸ©é˜µ**ï¼šé’ˆå¯¹DeepSeek/è±†åŒ…/Kimiç­‰çš„å®šå‘å†…å®¹æŠ•å–‚
- **å“ç‰Œè¯ä½“ç³»å»ºè®¾**ï¼šæ ¸å¿ƒè¯+é•¿å°¾é—®å¥ã€æ’è¡Œæ¦œå†…å®¹ã€å¯¹æ¯”è¯æœ¯
- **æƒå¨èƒŒä¹¦æ„å»º**ï¼šä¸“å®¶çŸ©é˜µã€ç‹¬å®¶æ•°æ®ã€ç¬¬ä¸‰æ–¹è®¤è¯ã€åª’ä½“æåŠ
- **å±æœºé¢„è­¦æœºåˆ¶**ï¼šAIçˆ¬è™«ç›‘æµ‹ã€è´Ÿé¢èˆ†æƒ…å¿«é€Ÿå“åº”ã€å†…å®¹çº å
- **ç”¨æˆ·åœºæ™¯åŒ–è¡¨è¾¾**ï¼šå°†æŠ€æœ¯å‚æ•°è½¬åŒ–ä¸ºç”¨æˆ·ä»·å€¼ã€çœŸå®æ•…äº‹ã€UGCå…±åˆ›

**ç»´åº¦æ•°é‡å»ºè®®**ï¼š
- é«˜å±é—®é¢˜é›†ä¸­åœ¨å†…å®¹è´¨é‡/æƒå¨æ€§ â†’ 3-4ä¸ªæ·±åº¦ç»´åº¦
- é—®é¢˜æ¶‰åŠå¤šå¹³å°å¤šé¢†åŸŸ â†’ 5-6ä¸ªè¦†ç›–é¢å¹¿çš„ç»´åº¦
- æ—¢æœ‰ç´§æ€¥å±æœºåˆéœ€é•¿æœŸå»ºè®¾ â†’ 4-5ä¸ªçŸ­ä¸­é•¿æœŸç»“åˆçš„ç»´åº¦

# è¾“å‡ºè¦æ±‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ã€æ³¨é‡Šæˆ–è¯´æ˜ï¼š

{{
  "metadata": {{
    "ç”Ÿæˆæ—¶é—´": "{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
    "åˆ†ææ•°æ®æ¥æº": "èµ›åŠ›æ–¯èˆ†æƒ…åˆ†æç³»ç»Ÿ",
    "é«˜å±é—®é¢˜æ•°é‡": {high_risk_count},
    "é¢„è­¦é—®é¢˜æ•°é‡": {warning_count},
    "æ€»é—®é¢˜æ•°é‡": {high_risk_count + warning_count}
  }},
  "executive_summary": {{
    "æ ¸å¿ƒé—®é¢˜æ¦‚è¿°": "ç”¨2-3å¥è¯æ€»ç»“å½“å‰æœ€ä¸¥é‡çš„å£°èª‰é£é™©",
    "ç´§æ€¥ç¨‹åº¦è¯„ä¼°": "é«˜/ä¸­/ä½",
    "é¢„è®¡å½±å“èŒƒå›´": "æè¿°è¿™äº›é—®é¢˜å¯èƒ½å½±å“çš„ç”¨æˆ·ç¾¤ä½“å’Œå†³ç­–åœºæ™¯"
  }},
  "solutions": [
    {{
      "dimension": "ç»´åº¦1åç§°ï¼ˆæ ¹æ®å®é™…é—®é¢˜å’ŒGEOæ–¹æ³•è®ºç¡®å®šï¼‰",
      "priority": "é«˜/ä¸­/ä½",
      "target_problems": ["é’ˆå¯¹çš„æ ¸å¿ƒé—®é¢˜1", "é’ˆå¯¹çš„æ ¸å¿ƒé—®é¢˜2"],
      "strategy_overview": "è¯¥ç»´åº¦çš„æ•´ä½“ç­–ç•¥æè¿°ï¼ˆ200å­—å·¦å³ï¼‰ï¼Œå¿…é¡»åŸºäºGEOæ–¹æ³•è®º",
      "geo_principles": ["åº”ç”¨çš„GEOåŸåˆ™1ï¼ˆå¦‚ï¼šE-E-A-Tï¼‰", "åº”ç”¨çš„GEOåŸåˆ™2ï¼ˆå¦‚ï¼šSchemaæ ‡è®°ï¼‰"],
      "action_items": [
        {{
          "action": "å…·ä½“è¡ŒåŠ¨é¡¹æ ‡é¢˜",
          "description": "è¯¦ç»†æè¿°è¯¥è¡ŒåŠ¨é¡¹çš„æ‰§è¡Œæ–¹å¼ï¼ŒåŒ…å«å…·ä½“å¹³å°/å·¥å…·/æŠ€æœ¯",
          "geo_method": "å¯¹åº”çš„GEOæ–¹æ³•ï¼ˆå¦‚ï¼šç»“æ„åŒ–å†…å®¹ã€å¹³å°æŠ•å–‚ã€Schemaéƒ¨ç½²ç­‰ï¼‰",
          "platforms": ["ç›®æ ‡å¹³å°1ï¼ˆå¦‚ï¼šDeepSeekï¼‰", "ç›®æ ‡å¹³å°2ï¼ˆå¦‚ï¼šçŸ¥ä¹ï¼‰"],
          "expected_outcome": "é¢„æœŸæ•ˆæœ",
          "timeline": "æ‰§è¡Œæ—¶é—´çº¿ï¼ˆå¦‚ï¼š1-2å‘¨/1ä¸ªæœˆ/æŒç»­è¿›è¡Œï¼‰",
          "kpi": "å…³é”®ç»©æ•ˆæŒ‡æ ‡ï¼ˆå¦‚ï¼šAIå¯è§æ€§æŒ‡æ•°æå‡20%ï¼‰"
        }}
      ],
      "resources_needed": ["æ‰€éœ€èµ„æº1", "æ‰€éœ€èµ„æº2"],
      "risk_mitigation": "è¯¥ç­–ç•¥å¯èƒ½é‡åˆ°çš„é£é™©åŠåº”å¯¹æ–¹å¼"
    }},
    {{
      "dimension": "ç»´åº¦2åç§°ï¼ˆåŸºäºGEOæ–¹æ³•è®ºï¼‰",
      "priority": "é«˜/ä¸­/ä½",
      "target_problems": ["é’ˆå¯¹çš„æ ¸å¿ƒé—®é¢˜"],
      "strategy_overview": "ç­–ç•¥æè¿°",
      "geo_principles": ["GEOåŸåˆ™"],
      "action_items": [
        {{
          "action": "è¡ŒåŠ¨é¡¹",
          "description": "è¯¦ç»†æè¿°",
          "geo_method": "GEOæ–¹æ³•",
          "platforms": ["å¹³å°"],
          "expected_outcome": "é¢„æœŸæ•ˆæœ",
          "timeline": "æ—¶é—´çº¿",
          "kpi": "KPI"
        }}
      ],
      "resources_needed": ["èµ„æºéœ€æ±‚"],
      "risk_mitigation": "é£é™©åº”å¯¹"
    }},
    {{
      "dimension": "ç»´åº¦3åç§°",
      "priority": "é«˜/ä¸­/ä½",
      "target_problems": ["æ ¸å¿ƒé—®é¢˜"],
      "strategy_overview": "ç­–ç•¥æè¿°",
      "geo_principles": ["GEOåŸåˆ™"],
      "action_items": [
        {{
          "action": "è¡ŒåŠ¨é¡¹",
          "description": "æè¿°",
          "geo_method": "æ–¹æ³•",
          "platforms": ["å¹³å°"],
          "expected_outcome": "æ•ˆæœ",
          "timeline": "æ—¶é—´",
          "kpi": "æŒ‡æ ‡"
        }}
      ],
      "resources_needed": ["èµ„æº"],
      "risk_mitigation": "é£é™©"
    }}
    // æ ¹æ®å®é™…éœ€è¦ï¼Œå¯ä»¥æœ‰3-6ä¸ªç»´åº¦
    // æ¯ä¸ªç»´åº¦å¿…é¡»æ˜ç¡®å…³è”GEOæ–¹æ³•è®ºä¸­çš„å…·ä½“ç­–ç•¥
  ],
  "implementation_roadmap": {{
    "phase_1_immediate": {{
      "timeframe": "0-2å‘¨",
      "focus": "æœ€ç´§æ€¥çš„è¡ŒåŠ¨",
      "key_milestones": ["é‡Œç¨‹ç¢‘1", "é‡Œç¨‹ç¢‘2"]
    }},
    "phase_2_short_term": {{
      "timeframe": "2å‘¨-2ä¸ªæœˆ",
      "focus": "çŸ­æœŸæ”¹å–„",
      "key_milestones": ["é‡Œç¨‹ç¢‘"]
    }},
    "phase_3_long_term": {{
      "timeframe": "2-6ä¸ªæœˆ",
      "focus": "é•¿æœŸå»ºè®¾",
      "key_milestones": ["é‡Œç¨‹ç¢‘"]
    }}
  }},
  "success_metrics": {{
    "primary_kpis": [
      {{
        "indicator": "æŒ‡æ ‡åç§°",
        "current_baseline": "å½“å‰åŸºçº¿",
        "target_3_months": "3ä¸ªæœˆç›®æ ‡",
        "target_6_months": "6ä¸ªæœˆç›®æ ‡"
      }}
    ]
  }}
}}

å…³é”®è¦æ±‚ï¼š
1. **GEOæ–¹æ³•è®ºä¸ºæ ¸å¿ƒ**ï¼šæ‰€æœ‰ç­–ç•¥å¿…é¡»åŸºäºGEOæ–¹æ³•è®ºï¼Œæ˜ç¡®æ ‡æ³¨geo_principleså’Œgeo_method
2. **ç»´åº¦æ•°é‡çµæ´»**ï¼šæ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦å’Œè¦†ç›–é¢ï¼Œè¾“å‡º3-6ä¸ªç»´åº¦ï¼ˆå»ºè®®4-5ä¸ªï¼‰
3. **å¹³å°é’ˆå¯¹æ€§**ï¼šæ˜ç¡®æ¯ä¸ªè¡ŒåŠ¨é¡¹é’ˆå¯¹çš„AIå¹³å°ï¼ˆDeepSeek/è±†åŒ…/Kimi/å…ƒå®ç­‰ï¼‰
4. **æŠ€æœ¯å…·ä½“æ€§**ï¼šæ¶‰åŠæŠ€æœ¯æ‰‹æ®µæ—¶è¦å…·ä½“ï¼ˆå¦‚Schemaæ ‡è®°ã€LLMS.txtã€GEOHeadç­‰ï¼‰
5. **å†…å®¹å½¢å¼æ˜ç¡®**ï¼šå†…å®¹ç­–ç•¥è¦æ˜ç¡®å½¢å¼ï¼ˆæ’è¡Œæ¦œã€FAQã€é•¿å°¾é—®å¥ã€å¯¹æ¯”æ–‡ç« ç­‰ï¼‰
6. **å¯è¡¡é‡KPI**ï¼šKPIè¦å…·ä½“å¯è¡¡é‡ï¼ˆå¦‚AIå¯è§æ€§æŒ‡æ•°ã€å¼•ç”¨ç‡ã€çˆ¬è™«è®¿é—®é‡ç­‰ï¼‰
7. **ç»´åº¦å·®å¼‚æ€§**ï¼šå„ç»´åº¦ä¹‹é—´å¿…é¡»æœ‰æ˜æ˜¾åŒºåˆ«ï¼Œè¦†ç›–GEOæ–¹æ³•è®ºçš„ä¸åŒæ–¹é¢
8. **ä¼˜å…ˆçº§åˆç†**ï¼šé«˜å±é—®é¢˜å¯¹åº”çš„ç»´åº¦åº”æ ‡è®°ä¸º"é«˜"ä¼˜å…ˆçº§
9. **è¾“å‡ºå¿…é¡»æ˜¯çº¯JSONæ ¼å¼**ï¼Œå¯ä»¥è¢«æ ‡å‡†JSONè§£æå™¨è§£æ
10. **ä¸è¦ç”¨```json```åŒ…è£¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—**
"""
    
    return prompt

# ==================== è°ƒç”¨AIç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ ====================
def generate_solutions(critical_issues: Dict[str, List[Dict]], max_retries: int = 3) -> Dict:
    """è°ƒç”¨AIç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ"""
    
    print("\n" + "="*80)
    print("æ­£åœ¨ç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ...")
    print(f"- é«˜å±é—®é¢˜: {len(critical_issues['é«˜å±'])} ä¸ª")
    print(f"- é¢„è­¦é—®é¢˜: {len(critical_issues['é¢„è­¦'])} ä¸ª")
    print("="*80 + "\n")
    
    prompt = build_synthesis_prompt(critical_issues)
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                print(f"  ç¬¬ {attempt + 1} æ¬¡å°è¯•...")
            
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=8000
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # å°è¯•è§£æJSON
            try:
                result = json.loads(result_text)
                print("âœ“ è§£å†³æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼")
                return result
            except json.JSONDecodeError:
                # å°è¯•ä¿®å¤JSON
                print("  å°è¯•ä¿®å¤JSONæ ¼å¼...")
                repaired = repair_json(result_text)
                result = json.loads(repaired)
                print("âœ“ JSONä¿®å¤æˆåŠŸï¼Œè§£å†³æ–¹æ¡ˆç”Ÿæˆå®Œæˆï¼")
                return result
                
        except Exception as e:
            print(f"âœ— å°è¯• {attempt + 1} å¤±è´¥: {e}")
            if attempt == max_retries - 1:
                print(f"âœ— å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return {
                    "error": "ç”Ÿæˆå¤±è´¥",
                    "message": str(e),
                    "metadata": {
                        "ç”Ÿæˆæ—¶é—´": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        "é«˜å±é—®é¢˜æ•°é‡": len(critical_issues['é«˜å±']),
                        "é¢„è­¦é—®é¢˜æ•°é‡": len(critical_issues['é¢„è­¦'])
                    }
                }
    
    return {}

# ==================== ä¿å­˜è§£å†³æ–¹æ¡ˆ ====================
def save_solutions(solutions: Dict, output_dir: str = "solution"):
    """ä¿å­˜ç»¼åˆè§£å†³æ–¹æ¡ˆåˆ°JSONæ–‡ä»¶"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"ç»¼åˆè§£å†³æ–¹æ¡ˆ_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(solutions, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*80}")
    print(f"âœ“ ç»¼åˆè§£å†³æ–¹æ¡ˆå·²ä¿å­˜è‡³: {filepath}")
    
    # æ‰“å°æ‘˜è¦ä¿¡æ¯
    if "metadata" in solutions:
        metadata = solutions["metadata"]
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(f"  - é«˜å±é—®é¢˜: {metadata.get('é«˜å±é—®é¢˜æ•°é‡', 0)} ä¸ª")
        print(f"  - é¢„è­¦é—®é¢˜: {metadata.get('é¢„è­¦é—®é¢˜æ•°é‡', 0)} ä¸ª")
        print(f"  - æ€»é—®é¢˜æ•°: {metadata.get('æ€»é—®é¢˜æ•°é‡', 0)} ä¸ª")
    
    if "executive_summary" in solutions:
        summary = solutions["executive_summary"]
        print(f"\næ ¸å¿ƒæ‘˜è¦:")
        print(f"  - ç´§æ€¥ç¨‹åº¦: {summary.get('ç´§æ€¥ç¨‹åº¦è¯„ä¼°', 'N/A')}")
        print(f"  - é—®é¢˜æ¦‚è¿°: {summary.get('æ ¸å¿ƒé—®é¢˜æ¦‚è¿°', 'N/A')[:100]}...")
    
    if "solutions" in solutions:
        print(f"\nè§£å†³æ–¹æ¡ˆç»´åº¦: {len(solutions['solutions'])} ä¸ª")
        for idx, sol in enumerate(solutions['solutions'], 1):
            print(f"  {idx}. {sol.get('dimension', 'N/A')} (ä¼˜å…ˆçº§: {sol.get('priority', 'N/A')})")
    
    print(f"{'='*80}\n")
    
    return filepath

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    
    print("\n" + "="*80)
    print("èµ›åŠ›æ–¯/é—®ç•Œ èˆ†æƒ…åˆ†æç»¼åˆè§£å†³æ–¹æ¡ˆç”Ÿæˆå·¥å…·".center(80))
    print("="*80 + "\n")
    
    # æ£€æŸ¥APIå¯†é’¥
    if not API_KEY:
        print("âš ï¸  é”™è¯¯: è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®API_KEY")
        return
    
    # æ‰«æåˆ†æç»“æœæ–‡ä»¶
    analysis_dir = "analysis_results"
    files = scan_analysis_files(analysis_dir)
    
    if not files:
        print(f"\nâš ï¸  åœ¨ {analysis_dir} ç›®å½•ä¸‹æœªæ‰¾åˆ°åˆ†æç»“æœæ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(files)} ä¸ªåˆ†æç»“æœæ–‡ä»¶:")
    for idx, file in enumerate(files, 1):
        print(f"  {idx}. {os.path.basename(file)}")
    
    # åŠ è½½æ‰€æœ‰åˆ†ææ•°æ®
    print("\næ­£åœ¨åŠ è½½åˆ†ææ•°æ®...")
    all_data = []
    for file in files:
        data = load_analysis_data(file)
        all_data.extend(data)
    
    print(f"\nâœ“ å…±åŠ è½½ {len(all_data)} æ¡åˆ†ææ•°æ®")
    
    # æå–é¢„è­¦å’Œé«˜å±é—®é¢˜
    print("\næ­£åœ¨æå–é¢„è­¦å’Œé«˜å±é—®é¢˜...")
    critical_issues = extract_critical_issues(all_data)
    
    print(f"âœ“ æå–å®Œæˆ:")
    print(f"  - é«˜å±é—®é¢˜: {len(critical_issues['é«˜å±'])} ä¸ª")
    print(f"  - é¢„è­¦é—®é¢˜: {len(critical_issues['é¢„è­¦'])} ä¸ª")
    
    if len(critical_issues['é«˜å±']) == 0 and len(critical_issues['é¢„è­¦']) == 0:
        print("\nâœ“ å¤ªæ£’äº†ï¼æœªå‘ç°é«˜å±æˆ–é¢„è­¦é—®é¢˜")
        return
    
    # ç”Ÿæˆç»¼åˆè§£å†³æ–¹æ¡ˆ
    solutions = generate_solutions(critical_issues)
    
    # ä¿å­˜è§£å†³æ–¹æ¡ˆåˆ°solutionç›®å½•
    if solutions and "error" not in solutions:
        output_file = save_solutions(solutions, output_dir="solution")
        print(f"âœ“ ä»»åŠ¡å®Œæˆï¼")
        print(f"ä¸‹ä¸€æ­¥: å¯ä»¥ä½¿ç”¨è¯¥JSONæ–‡ä»¶è¿›è¡Œå¯è§†åŒ–å±•ç¤º")
    else:
        print("\nâœ— è§£å†³æ–¹æ¡ˆç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()

